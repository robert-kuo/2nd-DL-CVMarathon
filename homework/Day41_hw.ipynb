{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:493: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:494: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:495: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:496: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:497: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:502: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "# 將 train.py 所需要的套件載入\n",
    "import numpy as np\n",
    "import keras.backend as K\n",
    "from keras.layers import Input, Lambda\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "from yolo3.model import preprocess_true_boxes, yolo_body, tiny_yolo_body, yolo_loss\n",
    "from yolo3.utils import get_random_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create YOLOv3 model with 9 anchors and 20 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\keras\\engine\\saving.py:1140: UserWarning: Skipping loading of weights for layer conv2d_59 due to mismatch in shape ((1, 1, 1024, 75) vs (255, 1024, 1, 1)).\n",
      "  weight_values[i].shape))\n",
      "C:\\Anaconda3\\lib\\site-packages\\keras\\engine\\saving.py:1140: UserWarning: Skipping loading of weights for layer conv2d_59 due to mismatch in shape ((75,) vs (255,)).\n",
      "  weight_values[i].shape))\n",
      "C:\\Anaconda3\\lib\\site-packages\\keras\\engine\\saving.py:1140: UserWarning: Skipping loading of weights for layer conv2d_67 due to mismatch in shape ((1, 1, 512, 75) vs (255, 512, 1, 1)).\n",
      "  weight_values[i].shape))\n",
      "C:\\Anaconda3\\lib\\site-packages\\keras\\engine\\saving.py:1140: UserWarning: Skipping loading of weights for layer conv2d_67 due to mismatch in shape ((75,) vs (255,)).\n",
      "  weight_values[i].shape))\n",
      "C:\\Anaconda3\\lib\\site-packages\\keras\\engine\\saving.py:1140: UserWarning: Skipping loading of weights for layer conv2d_75 due to mismatch in shape ((1, 1, 256, 75) vs (255, 256, 1, 1)).\n",
      "  weight_values[i].shape))\n",
      "C:\\Anaconda3\\lib\\site-packages\\keras\\engine\\saving.py:1140: UserWarning: Skipping loading of weights for layer conv2d_75 due to mismatch in shape ((75,) vs (255,)).\n",
      "  weight_values[i].shape))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load weights model_data/yolo_weights.h5.\n",
      "Freeze the first 249 layers of total 252 layers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\dask\\dataframe\\utils.py:14: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 90 samples, val on 10 samples, with batch size 16.\n",
      "Epoch 1/50\n"
     ]
    }
   ],
   "source": [
    "from train import get_classes, get_anchors, create_model, create_tiny_model, data_generator, data_generator_wrapper\n",
    "\n",
    "annotation_path = '2007_train.txt' # 轉換好格式的標註檔案\n",
    "log_dir = 'logs/000/' # 訓練好的模型儲存的路徑\n",
    "classes_path = 'model_data/voc_classes.txt'\n",
    "anchors_path = 'model_data/yolo_anchors.txt'\n",
    "class_names = get_classes(classes_path)\n",
    "num_classes = len(class_names)\n",
    "anchors = get_anchors(anchors_path)\n",
    "\n",
    "input_shape = (416,416) # multiple of 32, hw\n",
    "\n",
    "is_tiny_version = len(anchors)==6 # default setting\n",
    "if is_tiny_version:\n",
    "    model = create_tiny_model(input_shape, anchors, num_classes,\n",
    "        freeze_body=2, weights_path='model_data/tiny_yolo_weights.h5')\n",
    "else:\n",
    "    model = create_model(input_shape, anchors, num_classes,\n",
    "        freeze_body=2, weights_path='model_data/yolo_weights.h5') # make sure you know what you freeze\n",
    "\n",
    "logging = TensorBoard(log_dir=log_dir)\n",
    "checkpoint = ModelCheckpoint(log_dir + 'ep{epoch:03d}-loss{loss:.3f}-val_loss{val_loss:.3f}.h5',\n",
    "    monitor='val_loss', save_weights_only=True, save_best_only=True, period=3)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1)\n",
    "\n",
    "# 分為 training 以及 validation\n",
    "val_split = 0.1\n",
    "with open(annotation_path) as f:\n",
    "    lines = f.readlines()\n",
    "np.random.seed(10101)\n",
    "np.random.shuffle(lines)\n",
    "np.random.seed(None)\n",
    "num_val = int(len(lines)*val_split)\n",
    "num_train = len(lines) - num_val\n",
    "\n",
    "# Train with frozen layers first, to get a stable loss.\n",
    "# Adjust num epochs to your dataset. This step is enough to obtain a not bad model.\n",
    "# 一開始先 freeze YOLO 除了 output layer 以外的 darknet53 backbone 來 train\n",
    "if True:\n",
    "    model.compile(optimizer=Adam(lr=1e-3), loss={\n",
    "        # use custom yolo_loss Lambda layer.\n",
    "        'yolo_loss': lambda y_true, y_pred: y_pred})\n",
    "\n",
    "    batch_size = 16\n",
    "    print('Train on {} samples, val on {} samples, with batch size {}.'.format(num_train, num_val, batch_size))\n",
    "    # 模型利用 generator 產生的資料做訓練，強烈建議大家去閱讀及理解 data_generator_wrapper 在 train.py 中的實現\n",
    "    model.fit_generator(data_generator_wrapper(lines[:num_train], batch_size, input_shape, anchors, num_classes),\n",
    "            steps_per_epoch=max(1, num_train//batch_size),\n",
    "            validation_data=data_generator_wrapper(lines[num_train:], batch_size, input_shape, anchors, num_classes),\n",
    "            validation_steps=max(1, num_val//batch_size),\n",
    "            epochs=50,\n",
    "            initial_epoch=0,\n",
    "            callbacks=[logging, checkpoint])\n",
    "    model.save_weights(log_dir + 'trained_weights_stage_1.h5')\n",
    "\n",
    "# Unfreeze and continue training, to fine-tune.\n",
    "# Train longer if the result is not good.\n",
    "if True:\n",
    "    # 把所有 layer 都改為 trainable\n",
    "    for i in range(len(model.layers)):\n",
    "        model.layers[i].trainable = True\n",
    "    model.compile(optimizer=Adam(lr=1e-4), loss={'yolo_loss': lambda y_true, y_pred: y_pred}) # recompile to apply the change\n",
    "    print('Unfreeze all of the layers.')\n",
    "\n",
    "    batch_size = 16 # note that more GPU memory is required after unfreezing the body\n",
    "    print('Train on {} samples, val on {} samples, with batch size {}.'.format(num_train, num_val, batch_size))\n",
    "    model.fit_generator(data_generator_wrapper(lines[:num_train], batch_size, input_shape, anchors, num_classes),\n",
    "        steps_per_epoch=max(1, num_train//batch_size),\n",
    "        validation_data=data_generator_wrapper(lines[num_train:], batch_size, input_shape, anchors, num_classes),\n",
    "        validation_steps=max(1, num_val//batch_size),\n",
    "        epochs=100,\n",
    "        initial_epoch=50,\n",
    "        callbacks=[logging, checkpoint, reduce_lr, early_stopping])\n",
    "    model.save_weights(log_dir + 'trained_weights_final.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "image = Image.open('c:\\\\home\\\\dog.jpg') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yolo import YOLO\n",
    "yolo_model = YOLO(model_path=log_dir + 'trained_weights_final.h5', classes_path=classes_path)\n",
    "r_image = yolo_model.detect_image(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"2007_train.txt\", \"r\") as f:\n",
    "  d = f.readlines()\n",
    "d"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
